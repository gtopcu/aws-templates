import boto3
from boto3.dynamodb.conditions import Key
from botocore.exceptions import ClientError
from itertools import islice

# Adds missing items from table1 on source_aws to table2 on target_aws accounts

# AWS credentials for source and target accounts
SOURCE_AWS = {
    'aws_access_key_id': 'SOURCE_ACCESS_KEY',
    'aws_secret_access_key': 'SOURCE_SECRET_KEY',
    'region_name': 'us-east-1'
}

TARGET_AWS = {
    'aws_access_key_id': 'TARGET_ACCESS_KEY',
    'aws_secret_access_key': 'TARGET_SECRET_KEY',
    'region_name': 'us-east-1'
}

# DynamoDB table names
SOURCE_TABLE_NAME = 'YourSourceTable'
TARGET_TABLE_NAME = 'YourTargetTable'

# Keys used as primary and sort keys
PK_NAME = 'PK'
SK_NAME = 'SK'

# Batch size limits
BATCH_GET_SIZE = 100
BATCH_WRITE_SIZE = 25


def chunked(iterable, size):
    """Yield successive chunks from iterable."""
    it = iter(iterable)
    return iter(lambda: list(islice(it, size)), [])


def get_all_keys(ddb, table_name):
    """Scan entire table and return set of (PK, SK) tuples."""
    table = ddb.Table(table_name)
    keys = set()
    response = table.scan(ProjectionExpression=f"{PK_NAME}, {SK_NAME}")
    items = response.get('Items', [])
    keys.update((item[PK_NAME], item[SK_NAME]) for item in items)

    while 'LastEvaluatedKey' in response:
        response = table.scan(
            ProjectionExpression=f"{PK_NAME}, {SK_NAME}",
            ExclusiveStartKey=response['LastEvaluatedKey']
        )
        items = response.get('Items', [])
        keys.update((item[PK_NAME], item[SK_NAME]) for item in items)

    return keys


def get_items_by_keys(ddb, table_name, keys):
    """Fetch full items from source table by list of keys."""
    table = ddb.Table(table_name)
    items = []

    for key_chunk in chunked(keys, BATCH_GET_SIZE):
        request_keys = [{PK_NAME: pk, SK_NAME: sk} for pk, sk in key_chunk]
        response = ddb.batch_get_item(
            RequestItems={
                table_name: {
                    'Keys': request_keys
                }
            }
        )
        items.extend(response['Responses'].get(table_name, []))

    return items


def batch_write_items(dynamodb_resource, table_name, items):
    """Write items to target table in batch."""
    table = dynamodb_resource.Table(table_name)

    with table.batch_writer(overwrite_by_pkeys=[PK_NAME, SK_NAME]) as writer:
        for item in items:
            writer.put_item(Item=item)


def main():
    # Create separate sessions for source and target
    source_session = boto3.Session(**SOURCE_AWS)
    target_session = boto3.Session(**TARGET_AWS)

    source_dynamodb = source_session.resource('dynamodb')
    target_dynamodb = target_session.resource('dynamodb')

    print("üîç Scanning source table...")
    source_keys = get_all_keys(source_dynamodb, SOURCE_TABLE_NAME)

    print("üîç Scanning target table...")
    target_keys = get_all_keys(target_dynamodb, TARGET_TABLE_NAME)

    missing_keys = list(source_keys - target_keys)
    print(f"‚û°Ô∏è Found {len(missing_keys)} missing items to copy...")

    if not missing_keys:
        print("‚úÖ Target table is already up to date.")
        return

    # Fetch missing items from source
    print("üì¶ Fetching missing items from source table...")
    missing_items = get_items_by_keys(source_dynamodb, SOURCE_TABLE_NAME, missing_keys)

    # Write to target
    print("üìù Writing missing items to target table...")
    batch_write_items(target_dynamodb, TARGET_TABLE_NAME, missing_items)

    print("‚úÖ Sync complete!")


if __name__ == '__main__':
    main()
